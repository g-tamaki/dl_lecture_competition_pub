{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### glu層を入れたモデル\n",
    "image_featの標準化、チャネル正規化, subject_id = 0, im_feat標準化なしin loss  \n",
    "ConvBlock(in_channels, hid_dim), ConvBlock(hid_dim, hid_dim),  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001   2975(101)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.0005  3370(102)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.0002  3180(103)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.0001  2391(104)  \n",
    "\n",
    "hid_dim=64, p_drop=0.1, lr=0.001   3235(105)  \n",
    "hid_dim=64, p_drop=0.1, lr=0.0005  3307(106)  \n",
    "hid_dim=64, p_drop=0.1, lr=0.0002  2975(107)  \n",
    "hid_dim=64, p_drop=0.1, lr=0.0001  2857(108)  \n",
    "\n",
    "hid_dim=32, p_drop=0.1, lr=0.001   3235(109)  \n",
    "hid_dim=32, p_drop=0.1, lr=0.0005  3259(110)  \n",
    "hid_dim=32, p_drop=0.1, lr=0.0002  2999(111)  \n",
    "hid_dim=32, p_drop=0.1, lr=0.0001  2833(112)  \n",
    "あまり上がらない..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dilated conv する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_sizeを大きくする  \n",
    "\n",
    "image_featの標準化、チャネル正規化, subject_id = 0, im_feat標準化なしin loss  \n",
    "ConvBlock(in_channels, hid_dim), ConvBlock(hid_dim, hid_dim),glu層入れてない  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=128   3330(113)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=256   3546(114)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=512   3827(115)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=1024   5189(116)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=2048   6239(平均的には3500ぐらい)(117) 未学習  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=4096   4447(118)未学習  \n",
    "\n",
    "batch_sizeを大きくすると、最大のスコアは上がるが、揺れが激しくなる  \n",
    "batch_size=2048では、train_accが0.02レベル(val_accより小さい)だけどなぜ？  \n",
    "→ batch_sizeを大きくすると、スコアが上がる理由は、batch内で損失関数を計算していて、不正解を多く知れるからでは？  \n",
    "→ 逆に、正解を不正解にする力も間違えて入ってしまう。これが学習を妨げているのでは？  \n",
    "\n",
    "\n",
    "学習率を小さくすれば、振動が和らぐ？\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを増やす（）  \n",
    "自己強化学習(MAE)  どのようにmaskをかけるべきか?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logit_scaleをパラメータ化した\n",
    "image_featの標準化、チャネル正規化, subject_id = 0, im_feat標準化なしin loss  \n",
    "ConvBlock(in_channels, hid_dim), ConvBlock(hid_dim, hid_dim),glu層入れてない  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=128   3217(119)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=256   3462(120)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=512   4774(121)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=1024   5365(122)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=2048   6548(123) 未学習  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=4096   4472(124)未学習  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全データを用いる  \n",
    "image_featの標準化、チャネル正規化, im_feat標準化なしin loss, logit_scaleをパラメータ化  \n",
    "ConvBlock(in_channels, hid_dim), ConvBlock(hid_dim, hid_dim),glu層入れてない  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=128   0.034()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=256   0.033()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=512   0.032()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=1024   0.032()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=2048   0.030()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=4096   ()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convをsubject_idx毎に学習し、最後のDensLayerは共通化  \n",
    "image_featの標準化、チャネル正規化, im_feat標準化なしin loss, logit_scaleをパラメータ化  \n",
    "ConvBlock(in_channels, hid_dim), ConvBlock(hid_dim, hid_dim),glu層入れてない  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=128   0.046 ()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=256   0.047 ()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=512   0.048 ()  public:0.04771(修正後)  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=1024   0.044()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=2048   0.044()  \n",
    "hid_dim=128, p_drop=0.1, lr=0.001, batch_size=4096   0.045()  public:0.00487(おかしい、修正前)  \n",
    "10回以上改善しなかったら打ち切り  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
